{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f35ea7ed-c539-498b-929e-26ffa7686156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keena\\AppData\\Local\\Temp\\ipykernel_23168\\669913939.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['title'] + ' ' + df['description']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "# Used for confusion model which is to tell you how accurate your model is\n",
    "from sklearn import metrics\n",
    "# Removing filler words\n",
    "from nltk.corpus import stopwords\n",
    "# Simplifying words to base value\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Train test split (66% train - 33% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Used for making str into int (kind of)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection  import KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Logistic Regression model computes probability of an outcome based on an input variable(s)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "df1 = pd.read_csv(r'C:\\\\Users\\keena\\\\Desktop\\\\ML & AI\\\\militaria_products_data.csv',delimiter='|')\n",
    "\n",
    "df = df1.loc[(df1['conflict'].notnull())&(df1['nation'].notnull())&(df1['item_type'].notnull())]\n",
    "# df1.dropna(subset=['conflict','nation','item_type']) I think this does the same thing but in place.\n",
    "\n",
    "df['text'] = df['title'] + ' ' + df['description']\n",
    "data = df[['text','conflict','nation','item_type']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee669b4c-8763-478b-8cf1-19d7b22d6b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "url                 0\n",
      "price               0\n",
      "available           0\n",
      "date                0\n",
      "site                0\n",
      "id                  0\n",
      "currency            0\n",
      "description         2\n",
      "title              53\n",
      "nation           6409\n",
      "conflict        15289\n",
      "extracted_id    32921\n",
      "item_type       33935\n",
      "date_sold       49740\n",
      "grade           73131\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['text'].isna().sum())\n",
    "print(data['item_type'].isna().sum())\n",
    "print(df1.isna().sum().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20f1767-ab84-4664-b6d8-15498a3e8c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keena\\AppData\\Local\\Temp\\ipykernel_23168\\1887581878.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'] = corpus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2     german wwi officer shoulder board ir original ...\n",
       "9     insignia cloth british british wwii army shoul...\n",
       "18    u wwii army nurse corp blue belted jacket nurs...\n",
       "31    german wwi dress bayonet frog original era man...\n",
       "40    insignia metal u wwii usa captain sweetheart p...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = list(data['text'].dropna())\n",
    "# Preprocess the text / data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Corpus is used when having a list of lists used for analysis\n",
    "corpus = []\n",
    "#Condensing the text to only key components\n",
    "for i in range(len(text)):\n",
    "    # Replace any non letters with ' ' with text[i] being the current iteration\n",
    "    r = re.sub('[^a-zA-Z]',' ',text[i])\n",
    "    # Make everything lowercase\n",
    "    r = r.lower()\n",
    "    # Split every word into an item in a list\n",
    "    r = r.split()\n",
    "    # Remove all stopwords / filler words\n",
    "    r = [word for word in r if word not in stopwords.words('english')]\n",
    "    # Reduce words to base word\n",
    "    r = [lemmatizer.lemmatize(word) for word in r]\n",
    "    # Reconnect all the words in a list back into one list item\n",
    "    r = ' '.join(r)\n",
    "    # Put this singular list with all the cleaned words into 'corpus'\n",
    "    corpus.append(r)\n",
    "data['text'] = corpus\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3634101f-73d7-4aa1-80e9-a24efec85308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent Variable, what you have.\n",
    "X = data['text']\n",
    "# Dependent Variable, what you want.\n",
    "y  = data['item_type']\n",
    "y2 = data['conflict']\n",
    "y3 = data['nation']\n",
    "\n",
    "# Split the data to train / test\n",
    "X_train, X_test, y_train, y_test   = train_test_split(X, y, test_size=0.33, random_state=111)\n",
    "X_train, X_test, y2_train, y2_test = train_test_split(X, y2, test_size=0.33, random_state=111)\n",
    "X_train, X_test, y3_train, y3_test = train_test_split(X, y3, test_size=0.33, random_state=111)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c540f58e-b90b-412e-be6e-34a819a1cd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EDGED_WEAPONS', 'UNIFORM', 'INSIGNIA', ..., 'HELMET',\n",
       "       'EDGED_WEAPONS', 'MEDALS_AWARDS'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "lr = LogisticRegression()\n",
    "lr2 = LogisticRegression()\n",
    "lr3 = LogisticRegression()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "\n",
    "lr.fit(X_train_cv,y_train)\n",
    "lr2.fit(X_train_cv,y2_train)\n",
    "lr3.fit(X_train_cv,y3_train)\n",
    "\n",
    "# Convert all the data sets into numeric values for ML to read.\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "X_train_cv.shape\n",
    "\n",
    "predictions = lr.predict(X_test_cv)\n",
    "predictions2 = lr2.predict(X_test_cv)\n",
    "predictions3 = lr3.predict(X_test_cv)\n",
    "\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f91b83e6-d812-4657-b840-52ef3da43bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1fe1500-d347-47cf-a623-02ea0aa39f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "          ART       0.97      0.85      0.91        73\n",
      "BELTS_BUCKLES       0.98      0.98      0.98       874\n",
      "EDGED_WEAPONS       0.98      0.98      0.98      1633\n",
      "   FIELD_GEAR       0.98      0.97      0.98      1010\n",
      "         FLAG       0.97      0.94      0.95       476\n",
      "     HEADGEAR       0.98      0.97      0.98       678\n",
      "       HELMET       0.97      0.98      0.98       846\n",
      "     INSIGNIA       0.96      0.98      0.97      1865\n",
      "MEDALS_AWARDS       0.98      0.98      0.98      1699\n",
      "    PAPERWORK       0.95      0.93      0.94       196\n",
      "     POSTCARD       0.98      1.00      0.99       260\n",
      "       TINNIE       1.00      0.99      0.99       210\n",
      "      UNIFORM       0.96      0.96      0.96       862\n",
      "\n",
      "     accuracy                           0.97     10682\n",
      "    macro avg       0.97      0.96      0.97     10682\n",
      " weighted avg       0.97      0.97      0.97     10682\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CIVIL_WAR       0.97      0.98      0.98       184\n",
      "      COLD_WAR       0.98      0.92      0.95       115\n",
      "     INTER_WAR       0.80      0.80      0.80         5\n",
      "    KOREAN_WAR       0.94      0.86      0.90        58\n",
      "POST_CIVIL_WAR       0.98      0.96      0.97       116\n",
      "       PRE_WW2       0.73      0.54      0.62       351\n",
      "   VIETNAM_WAR       0.96      0.94      0.95        71\n",
      "           WW1       0.97      0.97      0.97      1725\n",
      "           WW2       0.97      0.99      0.98      8057\n",
      "\n",
      "      accuracy                           0.97     10682\n",
      "     macro avg       0.92      0.89      0.90     10682\n",
      "  weighted avg       0.96      0.97      0.97     10682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\keena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\keena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     AUSTRALIA       1.00      0.60      0.75        15\n",
      "       AUSTRIA       0.94      0.91      0.92        64\n",
      "       BELGIUM       1.00      0.78      0.88        27\n",
      "      BULGARIA       1.00      0.64      0.78        11\n",
      "        CANADA       1.00      0.63      0.77        19\n",
      "         CHINA       0.60      0.38      0.46         8\n",
      "CZECHOSLOVAKIA       1.00      0.36      0.53        14\n",
      "       DENMARK       0.00      0.00      0.00         1\n",
      "       FINLAND       1.00      0.71      0.83         7\n",
      "        FRANCE       0.93      0.91      0.92       106\n",
      "       GERMANY       0.99      0.99      0.99      6866\n",
      "         ITALY       0.92      0.90      0.91        84\n",
      "         JAPAN       0.99      0.98      0.98       590\n",
      "   NETHERLANDS       0.71      0.45      0.56        11\n",
      "        POLAND       0.85      0.69      0.76        16\n",
      "        POLISH       0.00      0.00      0.00         1\n",
      "       ROMANIA       1.00      0.33      0.50         6\n",
      "        RUSSIA       0.91      0.85      0.88       203\n",
      "         SPAIN       1.00      0.62      0.77        16\n",
      "        SWEDEN       0.00      0.00      0.00         3\n",
      "   SWITZERLAND       1.00      0.57      0.73         7\n",
      "            UK       0.97      0.97      0.97       303\n",
      "            US       0.96      0.98      0.97      2299\n",
      "    YUGOSLAVIA       0.00      0.00      0.00         5\n",
      "\n",
      "      accuracy                           0.98     10682\n",
      "     macro avg       0.78      0.59      0.66     10682\n",
      "  weighted avg       0.98      0.98      0.98     10682\n",
      "\n",
      "0.9691083423041558\n",
      "0.005654705532219135\n",
      "[0.96023578 0.97638577]\n"
     ]
    }
   ],
   "source": [
    "# This prints out an easy to understand report of how good the model is.\n",
    "print (classification_report(y_test, predictions))\n",
    "\n",
    "print (classification_report(y2_test, predictions2))\n",
    "\n",
    "print (classification_report(y3_test, predictions3))\n",
    "\n",
    "# This is to see how accurate our prediction model is.\n",
    "kf = KFold(n_splits=8, shuffle=True, random_state=5)\n",
    "cv_scores = cross_val_score(lr, X_test_cv, y_test, cv=kf)\n",
    "\n",
    "# Print the mean\n",
    "print(np.mean(cv_scores))\n",
    "\n",
    "# Print the standard deviation\n",
    "print(np.std(cv_scores))\n",
    "\n",
    "# Print the 95% confidence interval\n",
    "print(np.quantile(cv_scores, [0.025, 0.975]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3320d49-311a-4f33-a0e2-3b4c60db8849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    wwi german army buckle wwi german army buckle ...\n",
      "Name: testText, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdData = {'testText': [\"\"\"\n",
    "\n",
    "\n",
    "WWI GERMAN ARMY BUCKLE\n",
    "WWI German Army Buckle-This is an early steel combat buckle that retains the majority of its original olive-green finish. There is no visible wear. The reverse features a \"U\" shaped catch with steel roll bar and prongs. This is an excellent example of an early Heer buckle! \n",
    "\n",
    "\n",
    "\"\"\"]}\n",
    "\n",
    "tdf = pd.DataFrame(pdData)\n",
    "\n",
    "text = list(tdf['testText'].dropna())\n",
    "# Preprocess the text / data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Corpus is used when having a list of lists used for analysis\n",
    "corpus2 = []\n",
    "#Condensing the text to only key components\n",
    "for i in range(len(text)):\n",
    "    # Replace any non letters with ' ' with text[i] being the current iteration\n",
    "    r = re.sub('[^a-zA-Z]',' ',text[i])\n",
    "    # Make everything lowercase\n",
    "    r = r.lower()\n",
    "    # Split every word into an item in a list\n",
    "    r = r.split()\n",
    "    # Remove all stopwords / filler words\n",
    "    r = [word for word in r if word not in stopwords.words('english')]\n",
    "    # Reduce words to base word\n",
    "    r = [lemmatizer.lemmatize(word) for word in r]\n",
    "    # Reconnect all the words in a list back into one list item\n",
    "    r = ' '.join(r)\n",
    "    # Put this singular list with all the cleaned words into 'corpus'\n",
    "    corpus2.append(r)\n",
    "tdf['testText'] = corpus2\n",
    "print(tdf['testText'].head())\n",
    "\n",
    "tdfTest = tdf['testText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5128b53-b4a1-4aed-8bb5-1c80d4036cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITEM_TYPE PREDICTION :['BELTS_BUCKLES']\n",
      "CONFLICT PREDICTION  :['WW1']\n",
      "NATION PREDICTION    :['GERMANY']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tdfTest_cv = cv.transform(tdfTest)\n",
    "\n",
    "\n",
    "itemTypePrediction = lr.predict(tdfTest_cv)\n",
    "conflictPrediction = lr2.predict(tdfTest_cv)\n",
    "nationPrediction   = lr3.predict(tdfTest_cv)\n",
    "\n",
    "print(f'ITEM_TYPE PREDICTION :{itemTypePrediction}')\n",
    "print(f'CONFLICT PREDICTION  :{conflictPrediction}')\n",
    "print(f'NATION PREDICTION    :{nationPrediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f25cf-a92f-46ac-abdb-6b19ffeb6a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a13109-9bff-44c7-b2fb-90eebc47c90f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
